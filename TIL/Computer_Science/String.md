# 문자열 하나의 바이트

- 영어의 경우 알파벳 하나가 1바이트를 차지하던 시절이있었다.
- 현재의 글로벌 시대에는 유니코드를 사용해야 텍스트를 정확하게 저장할 수 있다.
- 프로그래밍 언어마다 문자열을 저장하는 자료형이 다르므로 자료향이 차지하고 있는 바이트를 이해하면 알수있다.

------

# Unicode(유니코드)

- 유니코드 협회가 제정하는  전 세계의 모든 문자를 컴퓨터에서 일관되게 표현하고 다룰 수 있도록 설계된 산업 표준이다.
- ISO 10646문자 집합, 문자 인코딩, 문자 정보 데이터 베이스, 문자를 다르기 위한 알고리즘 등을 포함하고 있다.

------

# Incoding(부호화)

- 인코딩이란 어떤 문자나 기호를 컴퓨터가 이용할 수 있는 신호로 만드는 것이다.
- 이 신호를 입력하는 인코딩과 문자를 해독하는 디코딩을 하기 위해서는 미리 정해진 기준을 바탕으로 입력과 해독이 처리되어야 한다.
- 이렇게 인코딩과 디코딩의 기준을 문자열 세트 또는 문자셋(charset)이라고 하며, 이 문자셋의 국제 표준이 유니코드입니다

------

# **ASCII**

- 영문 알파벳을 사용하는 대표적인 문자 인코딩으로 7 비트로 모든 영어 알파벳을 표현할 수 있다.
- 52개의 영문 알파벳 대소문자와, 10개의 숫자, 32개의 특수 문자, 그리고 하나의 공백 문자를 포함한다.
- 유니코드는 ASCII를 확장한 형태이다.

------

# UTF-8 과 UTF-16의 차이점

> UTF-8과 UTF-16은 인코딩 방식의 차이를 의미하며, UTF-8은 Universal Coded Character Set + Transformation Format – 8-bit의 약자로, UTF- 뒤에 등장하는 숫자는 비트(bit)이다.

## UTF-8

- 가변길이 인코딩
- 유니코드 한 문자를 나타내기 위해 1 byte(= 8 bits)에서 4 bytes까지 사용한다.
- 네트워크를 통해 전송되는 텍스트는 주로 UTF-8로 인코딩된다.
- UTF-8은 ASCII 코드의 경우 1 byte, 크게 영어 외 글자는 2byte, 3byte, 보조 글자는 4byte를 차지하며, 이모지는 보조 글자에 해당하기 때문에 4byte가 필요하다.
- UTF-16에 비해 바이트 순서를 따지지 않고, 순서가 정해져 있다.

## UTF-16

- UTF-16은 유니코드 코드 대부분(U+0000부터 U+FFFF; BMP) 을 16 bits로 표현한다.
- 대부분에 속하지 않는 기타 문자는 32 bit(4 bytes)로 표현하므로 UTF-16도 가변 길이라고 할 수 있으나, 대부분은 2 바이트로 표현한다.
- UTF-8에서는 한글은 3 바이트, UTF-16에서는 2 바이트를 차지한다.

## 원리

예를 들어, `코` 라는 문자의 유니코드는 `U+CF54` (16진수, HEX)로 표현된다. 이 문자를 이진법(binary number)으로 표시하면, `1100-1111-0101-0100` 이 된다. 이 문자를 UTF-8로 표현하면, 다음과 같이 3byte의 결과로 표현된다.

### UTF-8로 표현된 '코'

```jsx
1110xxxx 10xxxxxx 10xxxxxx // x 안에 순서대로 값을 채워는다.
11101100 10111101 10010100
```

### '코'라는 문자를 UTF-8로 표현

```jsx
let encoder = new TextEncoder(); // 기본 인코딩은 'utf-8'
encoder.encode('코') // Uint8Array(3) [236, 189, 148]

(236).toString(2) // "11101100"
(189).toString(2) // "10111101"
(148).toString(2) // "10010100"
```

### UTF-8로 표현된 'b’

```jsx
0xxxxxxx
01100010
```

### 'b'라는 문자를 UTF-8로 표현

```jsx
encoder.encode('b') // Uint8Array [98]
(98).toString(2) // "1100010"
```